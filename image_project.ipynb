{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA20001 Deep Learning - Group Project\n",
    "## Image project\n",
    "\n",
    "**Due Wednesday December 13, before 23:59.**\n",
    "\n",
    "The task is to learn to assign the correct labels to a set of images.  The images are originally from a photo-sharing site and released under Creative Commons-licenses allowing sharing.  The training set contains 20 000 images. We have resized them and cropped them to 128x128 to make the task a bit more manageable.\n",
    "\n",
    "We're only giving you the code for downloading the data. The rest you'll have to do yourselves.\n",
    "\n",
    "Some comments and hints particular to the image project:\n",
    "\n",
    "- One image may belong to many classes in this problem, i.e., it's a multi-label classification problem. In fact there are images that don't belong to any of our classes, and you should also be able to handle these correctly. Pay careful attention to how you design the outputs of the network (e.g., what activation to use) and what loss function should be used.\n",
    "\n",
    "- As the dataset is pretty imbalanced, don't focus too strictly on the outputs being probabilistic. (Meaning that the right threshold for selecting the label might not be 0.5.)\n",
    "\n",
    "- Image files can be loaded as numpy matrices for example using `imageio.imread`. Most images are color, but a few grayscale. You need to handle the grayscale ones somehow as they would have a different number of color channels (depth) than the color ones.\n",
    "\n",
    "- Loading all the images into one big matrix as we have done in the exercises is not feasible (e.g. the virtual servers in CSC have only 3 GB of RAM). You need to load the images in smaller chunks for the training. This shouldn't be a problem we are doing mini-batch training anyway, and thus we don't need to keep all the images in memory. You can simply pass you current chunk of images to `model.fit()` as it remembers the weights from the previous run.\n",
    "\n",
    "- You need to think carefully about how you load the annotations and match them up with the corresponding images, especially as you are loading them in smaller chunks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.data_utils import get_file\n",
    "\n",
    "database_path = 'train/'\n",
    "\n",
    "dl_file='dl2017-image-proj.zip'\n",
    "dl_url='https://www.cs.helsinki.fi/u/mvsjober/misc/'\n",
    "get_file(dl_file, dl_url+dl_file, cache_dir='./', cache_subdir=database_path, extract=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above command downloaded and extracted the data files into the `train` subdirectory.\n",
    "\n",
    "The images can be found in `train/images`, and are named as `im1.jpg`, `im2.jpg` and so on until `im20000.jpg`.\n",
    "\n",
    "The class labels, or annotations, can be found in `train/annotations` as `CLASSNAME.txt`, where CLASSNAME is one of the fourteen classes: *baby, bird, car, clouds, dog, female, flower, male, night, people, portrait, river, sea,* and *tree*.\n",
    "\n",
    "Each annotation file is a simple text file that lists the images that depict that class, one per line. The images are listed with their number, not the full filename. For example `5969` refers to the image `im5969.jpg`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your stuff goes here ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "from keras.layers.convolutional import *\n",
    "from keras.preprocessing.image import *\n",
    "from keras import backend as K\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.utils import np_utils\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy import misc\n",
    "from sklearn.metrics import f1_score\n",
    "from IPython.display import SVG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_indices = {0:\"baby\",\n",
    "                 1:\"bird\",\n",
    "                 2:\"car\",\n",
    "                 3:\"clouds\",\n",
    "                 4:\"dog\",\n",
    "                 5:\"female\",\n",
    "                 6:\"flower\",\n",
    "                 7:\"male\",\n",
    "                 8:\"night\",\n",
    "                 9:\"people\",\n",
    "                 10:\"portrait\",\n",
    "                 11:\"river\",\n",
    "                 12:\"sea\",\n",
    "                 13:\"tree\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Label and file name loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 20000\n",
    "num_class = len(class_indices)\n",
    "\n",
    "\n",
    "img_list = [database_path+\"images/\"+\"im\"+str(x)+\".jpg\" for x in range(1,N+1)]\n",
    "labels = np.zeros((N,num_class))\n",
    "\n",
    "for k,v in class_indices.items():\n",
    "    with open(database_path+\"annotations/\"+v+\".txt\",\"r\") as fp:\n",
    "        for line in fp:\n",
    "            labels[int(line)-1,k] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spliting train set and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_ratio = 0.8 #train:vad = 0.8\n",
    "img_size = (32,32)\n",
    "\n",
    "x_train_list, x_val_list, y_train, y_val = train_test_split(img_list,labels,test_size = 1-train_val_ratio,shuffle=True)\n",
    "image_load_func = lambda path: misc.imresize(misc.imread(path,mode=\"RGB\"),size=img_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img0 = image_load_func(x_train_list[0])\n",
    "for l in range(3):\n",
    "    plt.subplot(1, 4, l+1)\n",
    "    plt.imshow(img0[:,:,l])\n",
    "    plt.axis('off')\n",
    "plt.subplot(1, 4, 4)\n",
    "plt.imshow(img0)\n",
    "plt.axis('off')\n",
    "\n",
    "if sum(y_train[0]==1)==0:\n",
    "    print(\"No label\")\n",
    "else:\n",
    "    for i in np.argwhere(y_train[0]==1).flatten():\n",
    "        print(class_indices[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.stack([image_load_func(file) for file in x_train_list])\n",
    "x_val = np.stack([image_load_func(file) for file in x_val_list])\n",
    "print(x_train.shape,x_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from densenet import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Standard DenseNet with output layer adjusted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_filter=32\n",
    "weight_decay=0.00001\n",
    "dropout_rate=0.2\n",
    "nb_dense_block=3\n",
    "nb_layers=2\n",
    "growth_rate=12\n",
    "\n",
    "model = DenseNet(num_class, x_train.shape[1:], nb_layers*3+4, nb_dense_block, growth_rate,\n",
    "             nb_filter, dropout_rate=None, weight_decay=1E-4)\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer='adam')\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVG(model_to_dot(model, show_shapes=True).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "epochs = 3\n",
    "\n",
    "history = model.fit(x_train, \n",
    "                    y_train, \n",
    "                    epochs=epochs, \n",
    "                    batch_size=64,\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,3))\n",
    "plt.plot(history.epoch,history.history['loss'])\n",
    "plt.title('loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.rint(model.predict(x_val))\n",
    "print(\"micro averaged f1 score:\", f1_score(y_val, y_pred, average='micro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Customized DenseNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_filter=32\n",
    "weight_decay=0.00001\n",
    "dropout_rate=0.2\n",
    "nb_dense_block=3\n",
    "nb_layers=2\n",
    "growth_rate=1\n",
    "\n",
    "\n",
    "model_input = Input(shape=x_train.shape[1:])\n",
    "\n",
    "x = Conv2D(nb_filter, (3, 3),\n",
    "               kernel_initializer=\"he_uniform\",\n",
    "               padding=\"same\",\n",
    "               name=\"initial_conv2D\",\n",
    "               use_bias=True,\n",
    "               kernel_regularizer=l2(weight_decay))(model_input)\n",
    "#blocks\n",
    "for block_idx in range(nb_dense_block - 1):\n",
    "    x, nb_filter = denseblock(x, nb_layers, nb_filter, growth_rate,\n",
    "                              dropout_rate=dropout_rate)\n",
    "    # add transition\n",
    "    x = transition(x, nb_filter, dropout_rate=dropout_rate,\n",
    "                   weight_decay=weight_decay)\n",
    "\n",
    "#last block \n",
    "x, nb_filter = denseblock(x, nb_layers, nb_filter, growth_rate,\n",
    "                              dropout_rate=dropout_rate,\n",
    "                              weight_decay=weight_decay)\n",
    "\n",
    "x = BatchNormalization(axis=1,\n",
    "                       gamma_regularizer=l2(weight_decay),\n",
    "                       beta_regularizer=l2(weight_decay))(x)\n",
    "x = Activation('relu')(x)\n",
    "x = GlobalAveragePooling2D(data_format=K.image_data_format())(x)\n",
    "#linear\n",
    "\n",
    "model_output = Dense(num_class, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(inputs=[model_input], outputs=[model_output], name=\"DenseNet\")\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer='adam')\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVG(model_to_dot(model, show_shapes=True).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "epochs = 3\n",
    "\n",
    "history = model.fit(x_train, \n",
    "                    y_train, \n",
    "                    epochs=epochs, \n",
    "                    batch_size=64,\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,3))\n",
    "plt.plot(history.epoch,history.history['loss'])\n",
    "plt.title('loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.rint(model.predict(x_val))\n",
    "print(\"micro averaged f1 score:\", f1_score(y_val, y_pred, average='micro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classic ConvNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Conv2D(filters=32, kernel_size=(3, 3), input_shape=x_train.shape[1:],activation=\"relu\"))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(num_class,activation=\"sigmoid\"))\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer=opt)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "epochs = 3\n",
    "\n",
    "history = model.fit(x_train, \n",
    "                    y_train, \n",
    "                    epochs=epochs, \n",
    "                    batch_size=64,\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,3))\n",
    "plt.plot(history.epoch,history.history['loss'])\n",
    "plt.title('loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.rint(model.predict(x_val))\n",
    "print(\"micro averaged f1 score:\", f1_score(y_val, y_pred, average='micro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save your model\n",
    "\n",
    "It might be useful to save your model if you want to continue your work later, or use it for inference later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model file should now be visible in the \"Home\" screen of the jupyter notebooks interface.  There you should be able to select it and press \"download\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict for test set\n",
    "\n",
    "You will be asked to return your prediction for the testset.  These should be returned as a matrix with one row for each test set image.  Each row contains a binary prediction for each label, 1 if it's present in the image, and 0 if not. The order of the labels is as follows (alphabetic order of the label names):\n",
    "\n",
    "    baby bird car clouds dog female flower male night people portrait river sea tree\n",
    "\n",
    "An example row could like like this if your system predicts the presense of a bird and clouds:\n",
    "\n",
    "    0 1 0 1 0 0 0 0 0 0 0 0 0 0\n",
    "    \n",
    "If you have the matrix prepared in `y` (e.g., by calling `y=model.predict(x_test)`) you can use the following function to save it to a text file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('results.txt', y, fmt='%d')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
